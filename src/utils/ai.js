/**
 * AI Utility - Chu·∫©n h√≥a c√°c calls ƒë·∫øn GPT-4o-mini
 * Proxy qua /api/ai ƒë·ªÉ ·∫©n API key
 * C√≥ caching ƒë∆°n gi·∫£n ƒë·ªÉ ti·∫øt ki·ªám token
 */

// Cache in-memory (c√≥ th·ªÉ migrate sang localStorage n·∫øu c·∫ßn)
const cache = new Map();
const CACHE_TTL = 5 * 60 * 1000; // 5 ph√∫t

/**
 * T·∫°o cache key t·ª´ prompt v√† context
 */
function createCacheKey(role, prompt, context) {
  return JSON.stringify({ role, prompt, context: context || {} });
}

/**
 * Ki·ªÉm tra cache v√† tr·∫£ v·ªÅ n·∫øu c√≤n h·ª£p l·ªá
 */
function getFromCache(key) {
  const cached = cache.get(key);
  if (!cached) return null;
  
  const now = Date.now();
  if (now - cached.timestamp > CACHE_TTL) {
    cache.delete(key);
    return null;
  }
  
  return cached.data;
}

/**
 * L∆∞u v√†o cache
 */
function setCache(key, data) {
  cache.set(key, {
    data,
    timestamp: Date.now()
  });
}

/**
 * G·ª≠i prompt ƒë·∫øn AI model
 * @param {Object} params
 * @param {string} params.role - 'system' | 'user' | 'assistant'
 * @param {string} params.prompt - N·ªôi dung prompt
 * @param {Object} params.context - Context b·ªï sung (optional)
 * @param {boolean} params.useCache - C√≥ s·ª≠ d·ª•ng cache kh√¥ng (default: true)
 * @returns {Promise<string>} Response t·ª´ AI
 */
export async function sendPrompt({ role, prompt, context = {}, useCache = true }) {
  // Ki·ªÉm tra cache n·∫øu enable
  if (useCache) {
    const cacheKey = createCacheKey(role, prompt, context);
    const cached = getFromCache(cacheKey);
    if (cached) {
      return cached;
    }
  }

  try {
    // L·∫•y API base URL t·ª´ environment variable, fallback v·ªÅ relative path
    const apiBaseUrl = import.meta.env.VITE_API_BASE_URL || '';
    const apiUrl = apiBaseUrl ? `${apiBaseUrl}/api/ai` : '/api/ai';
    
    // Debug: log URL ƒëang g·ªçi
    console.log('üîó Calling API URL:', apiUrl);
    console.log('üîó VITE_API_BASE_URL:', import.meta.env.VITE_API_BASE_URL);
    
    const response = await fetch(apiUrl, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        role,
        prompt,
        context,
      }),
    });

    if (!response.ok) {
      throw new Error(`API Error: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    
    // Log response ƒë·ªÉ debug
    console.log('API Response:', data);
    
    // Ki·ªÉm tra n·∫øu c√≥ l·ªói t·ª´ backend
    if (data.error) {
      const errorMsg = data.message || data.error || 'Backend error';
      console.error('Backend error:', errorMsg);
      throw new Error(errorMsg);
    }
    
    const result = data.content || data.message || '';
    
    // N·∫øu result r·ªóng, throw error
    if (!result || result.trim().length === 0) {
      console.error('Empty response from API. Data received:', data);
      throw new Error('Empty response from API');
    }
    
    console.log('API Response content:', result.substring(0, 200));

    // L∆∞u v√†o cache n·∫øu enable
    if (useCache && result) {
      const cacheKey = createCacheKey(role, prompt, context);
      setCache(cacheKey, result);
    }

    return result;
  } catch (error) {
    console.error('AI call error:', error);
    
    // Fallback: tr·∫£ v·ªÅ mock response cho demo n·∫øu API ch∆∞a s·∫µn s√†ng
    if (error.message.includes('Failed to fetch') || error.message.includes('404')) {
      console.warn('API endpoint not available, using mock response');
      return generateMockResponse(role, prompt, context);
    }
    
    throw error;
  }
}

/**
 * Mock response cho demo (khi API ch∆∞a s·∫µn s√†ng)
 */
function generateMockResponse(role, prompt, context) {
  // Mock responses d·ª±a tr√™n role v√† prompt
  if (role === 'system') {
    return 'Mock system response';
  }
  
  // Mock responses cho c√°c demo
  if (prompt.includes('perception') || prompt.includes('intent')) {
    return JSON.stringify({
      intent: 'inquiry',
      tone: 'neutral',
      theme: 'information',
      mood: 'curious'
    });
  }
  
  if (prompt.includes('plan') || prompt.includes('step')) {
    return JSON.stringify({
      steps: [
        { id: 1, name: 'Step 1', description: 'Initial setup', status: 'pending' },
        { id: 2, name: 'Step 2', description: 'Process data', status: 'pending' },
        { id: 3, name: 'Step 3', description: 'Generate result', status: 'pending' }
      ]
    });
  }
  
  if (prompt.includes('tool') || prompt.includes('calculate')) {
    return JSON.stringify({
      tool: 'calculator',
      args: { operation: 'add', a: 5, b: 3 },
      result: 8
    });
  }
  
  return 'Mock AI response';
}

/**
 * Clear cache
 */
export function clearCache() {
  cache.clear();
}

/**
 * Get cache stats (for debugging)
 */
export function getCacheStats() {
  return {
    size: cache.size,
    entries: Array.from(cache.keys())
  };
}

